{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4134215",
   "metadata": {},
   "source": [
    "# Task 1: [IPO] Withdrawn IPOs by Company Type\n",
    "\n",
    "What is the total withdrawn IPO value (in $ millions) for the company class with the highest total withdrawal value?\n",
    "\n",
    "From the withdrawn IPO list (stockanalysis.com/ipos/withdrawn), collect and process the data to find out which company type saw the most withdrawn IPO value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9556e7b",
   "metadata": {},
   "source": [
    "## 1. Use pandas.read_html() with the URL above to load the IPO withdrawal table into a DataFrame. It is a similar process to Code Snippet 1 discussed at the livestream. You should get 99 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a24cd17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession started successfully!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "try:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Test\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    print(\"SparkSession started successfully!\")\n",
    "    spark.stop()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Failed to start SparkSession:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c59b3bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IPOWithdrawn\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Step 2: Scrape the page\n",
    "url = \"https://stockanalysis.com/ipos/withdrawn\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Step 3: Find the table\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Step 4: Extract headers\n",
    "headers = [th.text.strip() for th in table.find(\"thead\").find_all(\"th\")]\n",
    "\n",
    "# Step 5: Extract rows\n",
    "rows = []\n",
    "for tr in table.find(\"tbody\").find_all(\"tr\"):\n",
    "    cells = [td.text.strip() for td in tr.find_all(\"td\")]\n",
    "    rows.append(cells)\n",
    "\n",
    "# Step 6: Create Pandas DataFrame\n",
    "pandas_df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# Step 7: Convert to PySpark DataFrame\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4258a059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show result\n",
    "spark_df.filter(\"Symbol is not NULL\").select(\"Symbol\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ca9510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------------------------------+---------------+--------------+\n",
      "|Symbol|Company Name                                     |Price Range    |Shares Offered|\n",
      "+------+-------------------------------------------------+---------------+--------------+\n",
      "|PRB   |Peak Resources LP                                |$13.00 - $15.00|4,700,000     |\n",
      "|COC   |COR3 & Co. (Holdings) Limited                    |$4.00 - $5.00  |3,875,000     |\n",
      "|DIMR  |DiamiR Biosciences Corp.                         |-              |-             |\n",
      "|SLGB  |Smart Logistics Global Limited                   |$5.00 - $6.00  |1,000,000     |\n",
      "|EIL   |E I L Holdings Limited                           |-              |-             |\n",
      "|ODTX  |Odyssey Therapeutics, Inc.                       |-              |-             |\n",
      "|UNFL  |Unifoil Holdings, Inc.                           |$3.00 - $4.00  |2,000,000     |\n",
      "|AURN  |Aurion Biotech, Inc.                             |-              |-             |\n",
      "|ROTR  |PHI Group, Inc.                                  |-              |-             |\n",
      "|ONE   |One Power Company                                |-              |-             |\n",
      "|HPOT  |The Great Restaurant Development Holdings Limited|$4.00 - $6.00  |1,400,000     |\n",
      "|CABR  |Caring Brands, Inc.                              |$4.00          |750,000       |\n",
      "|SQVI  |Sequoia Vaccines, Inc.                           |$8.00 - $10.00 |2,775,000     |\n",
      "|SNI   |Shenni Holdings Limited                          |$4.00 - $6.00  |3,000,000     |\n",
      "|KMCM  |Key Mining Corp.                                 |$2.25          |4,444,444     |\n",
      "|XGEN  |GenEmbryomics Limited                            |$4.75          |1,095,000     |\n",
      "|JAG   |Job Aire Group Inc.                              |$4.50 - $5.50  |2,250,000     |\n",
      "|PYRO  |Pyro AI Inc.                                     |$4.00 - $5.00  |2,250,000     |\n",
      "|ORNC  |Oranco, Inc.                                     |$4.00 - $6.00  |1,500,000     |\n",
      "|KHIW  |Brilliance Group                                 |$4.00 - $5.00  |2,500,000     |\n",
      "+------+-------------------------------------------------+---------------+--------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecffa75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Symbol: string (nullable = true)\n",
      " |-- Company Name: string (nullable = true)\n",
      " |-- Price Range: string (nullable = true)\n",
      " |-- Shares Offered: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1801d93e",
   "metadata": {},
   "source": [
    "## 2. Create a new column called Company Class, categorizing company names based on patterns like:\n",
    "- “Acquisition Corp” or “Acquisition Corporation” → Acq.Corp\n",
    "- “Inc” or “Incorporated” → Inc\n",
    "- “Group” → Group\n",
    "- “Ltd” or “Limited” → Limited\n",
    "- “Holdings” → Holdings\n",
    "- Others → Other\n",
    "- Order: Please follow the listed order of classes and assign the first matched value (e.g., for 'shenni holdings limited', you assign the 'Limited' class).\n",
    "\n",
    "\n",
    "Hint: make your function more robust by converting names to lowercase and splitting into words before matching patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb150d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, lower, col\n",
    "\n",
    "# Start with your existing DataFrame `spark_df` that has a column like 'Name' or 'Company'\n",
    "# Replace 'Name' with the actual column name in your DataFrame\n",
    "\n",
    "# Define classification logic based on suffixes\n",
    "spark_df = spark_df.withColumn(\n",
    "    \"Class\",\n",
    "    when(lower(col(\"`Company Name`\")).rlike(r\"\\bacquisition corp(oration)?\\b\"), \"Acq.Corp\")\n",
    "    .when(lower(col(\"`Company Name`\")).rlike(r\"\\b(inc|incorporated)\\b\"), \"Inc\")\n",
    "    .when(lower(col(\"`Company Name`\")).rlike(r\"\\bgroup\\b\"), \"Group\")\n",
    "    .when(lower(col(\"`Company Name`\")).rlike(r\"\\b(ltd|limited)\\b\"), \"Limited\")\n",
    "    .when(lower(col(\"`Company Name`\")).rlike(r\"\\bholdings\\b\"), \"Holdings\")\n",
    "    .otherwise(\"Other\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9200e78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                        (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|   Class|count|\n",
      "+--------+-----+\n",
      "|     Inc|   50|\n",
      "|   Other|    8|\n",
      "| Limited|   20|\n",
      "|   Group|    3|\n",
      "|Holdings|    1|\n",
      "|Acq.Corp|   21|\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df.groupby(\"Class\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa2f21",
   "metadata": {},
   "source": [
    "## 3. Define a new field Avg. price by parsing the Price Range field (create a function and apply it to the Price Range column). Examples:\n",
    "- '$8.00-$10.00' → 9.0\n",
    "- '$5.00' → 5.0\n",
    "- '-' → None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab5fbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, regexp_extract, when\n",
    "\n",
    "# Objective: Parse Price Range to get average price\n",
    "# Method: Use regex to extract prices, handle ranges and single values\n",
    "\n",
    "# Get first price (e.g. $8.00)\n",
    "price_low = regexp_extract(col(\"Price Range\"), r\"\\$(\\d+\\.\\d+)\", 1)  # \\$ matches $, (\\d+\\.\\d+) captures digits.decimals\n",
    "\n",
    "# Get second price if range exists (e.g. $10.00)\n",
    "price_high = regexp_extract(col(\"Price Range\"), r\"\\$(?:\\d+\\.\\d+)\\s*-\\s*\\$(\\d+\\.\\d+)\", 1)  # non-capturing first price, capture second\n",
    "\n",
    "# Compute average price:\n",
    "# - If \"-\", set None\n",
    "# - If range, average both prices\n",
    "# - Else, use single price\n",
    "spark_df = spark_df.withColumn(\n",
    "    \"avg_price\",\n",
    "    when(col(\"Price Range\") == \"-\", None)\n",
    "    .when(price_high != \"\", (price_low.cast(\"float\") + price_high.cast(\"float\")) / 2)\n",
    "    .otherwise(price_low.cast(\"float\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f4928d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------------------------------+---------------+--------------+-------+---------+\n",
      "|Symbol|Company Name                                     |Price Range    |Shares Offered|Class  |avg_price|\n",
      "+------+-------------------------------------------------+---------------+--------------+-------+---------+\n",
      "|PRB   |Peak Resources LP                                |$13.00 - $15.00|4,700,000     |Other  |14.0     |\n",
      "|COC   |COR3 & Co. (Holdings) Limited                    |$4.00 - $5.00  |3,875,000     |Limited|4.5      |\n",
      "|DIMR  |DiamiR Biosciences Corp.                         |-              |-             |Other  |NULL     |\n",
      "|SLGB  |Smart Logistics Global Limited                   |$5.00 - $6.00  |1,000,000     |Limited|5.5      |\n",
      "|EIL   |E I L Holdings Limited                           |-              |-             |Limited|NULL     |\n",
      "|ODTX  |Odyssey Therapeutics, Inc.                       |-              |-             |Inc    |NULL     |\n",
      "|UNFL  |Unifoil Holdings, Inc.                           |$3.00 - $4.00  |2,000,000     |Inc    |3.5      |\n",
      "|AURN  |Aurion Biotech, Inc.                             |-              |-             |Inc    |NULL     |\n",
      "|ROTR  |PHI Group, Inc.                                  |-              |-             |Inc    |NULL     |\n",
      "|ONE   |One Power Company                                |-              |-             |Other  |NULL     |\n",
      "|HPOT  |The Great Restaurant Development Holdings Limited|$4.00 - $6.00  |1,400,000     |Limited|5.0      |\n",
      "|CABR  |Caring Brands, Inc.                              |$4.00          |750,000       |Inc    |4.0      |\n",
      "|SQVI  |Sequoia Vaccines, Inc.                           |$8.00 - $10.00 |2,775,000     |Inc    |9.0      |\n",
      "|SNI   |Shenni Holdings Limited                          |$4.00 - $6.00  |3,000,000     |Limited|5.0      |\n",
      "|KMCM  |Key Mining Corp.                                 |$2.25          |4,444,444     |Other  |2.25     |\n",
      "|XGEN  |GenEmbryomics Limited                            |$4.75          |1,095,000     |Limited|4.75     |\n",
      "|JAG   |Job Aire Group Inc.                              |$4.50 - $5.50  |2,250,000     |Inc    |5.0      |\n",
      "|PYRO  |Pyro AI Inc.                                     |$4.00 - $5.00  |2,250,000     |Inc    |4.5      |\n",
      "|ORNC  |Oranco, Inc.                                     |$4.00 - $6.00  |1,500,000     |Inc    |5.0      |\n",
      "|KHIW  |Brilliance Group                                 |$4.00 - $5.00  |2,500,000     |Group  |4.5      |\n",
      "+------+-------------------------------------------------+---------------+--------------+-------+---------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.show(truncate=False)\n",
    "spark_df.filter(\"avg_price is not NULL\").select(\"Symbol\").distinct().count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973731f0",
   "metadata": {},
   "source": [
    "### 5. Create a new column:\n",
    "Withdrawn Value = Shares Offered \\* Avg Price (71 non-null values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a3d8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, lit, col, regexp_replace\n",
    "\n",
    "spark_df = spark_df.withColumn(\n",
    "    \"share_offered_int\",\n",
    "    when((col(\"`Shares Offered`\") == \"-\") | (col(\"`Shares Offered`\") == \"\"), None)\n",
    "    .otherwise(regexp_replace(col(\"`Shares Offered`\"), \",\", \"\").cast(\"int\"))\n",
    ")\n",
    "df = spark_df.withColumn(\"withdrawn_value\", col(\"avg_price\") * col(\"share_offered_int\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed41acb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Symbol: string (nullable = true)\n",
      " |-- Company Name: string (nullable = true)\n",
      " |-- Price Range: string (nullable = true)\n",
      " |-- Shares Offered: string (nullable = true)\n",
      " |-- Class: string (nullable = false)\n",
      " |-- avg_price: double (nullable = true)\n",
      " |-- share_offered_int: integer (nullable = true)\n",
      " |-- withdrawn_value: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0944f986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+\n",
      "|class   |total_withdrawn_value|\n",
      "+--------+---------------------+\n",
      "|Acq.Corp|4.021E9              |\n",
      "|Inc     |2.257164234E9        |\n",
      "|Other   |8.33720015E8         |\n",
      "|Limited |5.726720855E8        |\n",
      "|Holdings|7.5E7                |\n",
      "|Group   |2.71875E7            |\n",
      "+--------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "from pyspark.sql.functions import col, sum as _sum\n",
    "\n",
    "df = df.withColumn(\"withdrawn_value_num\", col(\"withdrawn_value\").cast(\"float\"))\n",
    "\n",
    "df.groupby(\"class\").agg(\n",
    "    _sum(\"withdrawn_value_num\").alias(\"total_withdrawn_value\")\n",
    ").orderBy(col(\"total_withdrawn_value\").desc()).show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
